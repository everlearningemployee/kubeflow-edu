{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 201027 11:28:12 config:123] Using preprocessor: <kubeflow.fairing.preprocessors.converted_notebook.ConvertNotebookPreprocessor object at 0x7fa9abf60588>\n",
      "[I 201027 11:28:12 config:125] Using builder: <kubeflow.fairing.builders.append.append.AppendBuilder object at 0x7fa93008e240>\n",
      "[I 201027 11:28:12 config:127] Using deployer: <kubeflow.fairing.builders.append.append.AppendBuilder object at 0x7fa93008e240>\n",
      "[W 201027 11:28:12 append:50] Building image using Append builder...\n",
      "[I 201027 11:28:12 base:105] Creating docker context: /tmp/fairing_context_ys7rimw_\n",
      "[I 201027 11:28:12 converted_notebook:127] Converting 01-data-download.ipynb to 01-data-download.py\n",
      "[I 201027 11:28:12 docker_creds_:234] Loading Docker credentials for repository 'brightfly/kubeflow-jupyter-lab:tf2.0-cpu'\n",
      "[W 201027 11:28:14 append:54] Image successfully built in 2.3333871900103986s.\n",
      "[W 201027 11:28:14 append:94] Pushing image kubeflow-registry.default.svc.cluster.local:30000/datadownload-job:9A1FC451...\n",
      "[I 201027 11:28:14 docker_creds_:234] Loading Docker credentials for repository 'kubeflow-registry.default.svc.cluster.local:30000/datadownload-job:9A1FC451'\n",
      "[W 201027 11:28:14 append:81] Uploading kubeflow-registry.default.svc.cluster.local:30000/datadownload-job:9A1FC451\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:8e7d3ffcd500d3ed0b2ee2449a36a44601b8e282cc6d541ab93f1189d4a2cf93 exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:50f1fe304a9431ea025aa6ee5e8e45826fa62640a83e55be8bd3c227119cbcd2 exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:af228bb15b867acbee0d6df28dbb42a8218948fdde64833bd021a255a99a2690 exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:66257906239d377cd700c566b27f12895ccefcd8d95eae7377f600208151d8e0 exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:069de100aaecb1299b09dab29a4eb39a2ca6a5f8c0a033b65ff0e15e9ea39a24 exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:6ac505cbabeccba798e608e1bb80ae66f497c2c856733800e1db060e3c875917 exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:d0d480fe0d0ab233a90471379d9d3789d4153ad4611d101cfefdfc0c507d9356 exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:872efc07c3d848e0f55b7cbce9866a8dea7b76d8c1f131801934ea0d856b15c5 exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:fb9676c4102241f220b864e98c53676e27c407c6ecfbb13c2cbc1fa4de8f1811 exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:1c60aaf19cc4c142934f390281975f61956475c205b5895711f839a91f927779 exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:fd781ca227d0199735cceb67afa81e2a073b5ef5867ca6e96ad46e002a03252a exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:c2f81144f815902f9c6e6f7883068544e35924f0efe2275bc41c3d0c558f394c exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:7fc152dfb3a6b5c9a436b49ff6cd72ed7eb5f1fd349128b50ee04c3c5c2355fb exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:ee671aafb583e2321880e275c94d49a49185006730e871435cd851f42d2a775d exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:8f64ecfab6c102a62dd5d912d96113603663ad8b436701bf2dbd1aa9630882e7 exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:df80607e3e38dc3f117e967a36620c42f791afc9ca0568900d13d84c1e3a38bb exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:d846ead9aa38bc0d35dd500ada5349fe42efb96c89db08b8abcb9ad949332c2a exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:7acbfba21e38804c20c4da292d2f99d88d317b83440fb2f3de0a620edf2b9595 exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:5667fdb72017d1fb364744ca1abf7b6f3bbe9c98c3786f294a461c2866db69ab exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:485ea80d093de507a5ccd36effaf8dad03b67a1063edbd427fedfe667c9155bc exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:280] Layer sha256:d83811f270d56d34a208f721f3dbf1b9242d1900ad8981fc7071339681998a31 exists, skipping\n",
      "[I 201027 11:28:14 docker_session_:284] Layer sha256:80b44ee14cae46350dd4c17f043f115badad33003f2c8a697c03e20aedbc8a22 pushed.\n",
      "[I 201027 11:28:14 docker_session_:284] Layer sha256:a0194ad78606e66844b4799c5e6b1c1aa9f7ccec55ce58cb368fca5d4e8fdf5d pushed.\n",
      "[I 201027 11:28:14 docker_session_:334] Finished upload of: kubeflow-registry.default.svc.cluster.local:30000/datadownload-job:9A1FC451\n",
      "[W 201027 11:28:14 append:99] Pushed image kubeflow-registry.default.svc.cluster.local:30000/datadownload-job:9A1FC451 in 0.15000063506886363s.\n",
      "[W 201027 11:28:14 job:90] The job fairing-job-l47tg launched.\n",
      "[W 201027 11:28:15 manager:227] Waiting for fairing-job-l47tg-zhmqd to start...\n",
      "[W 201027 11:28:15 manager:227] Waiting for fairing-job-l47tg-zhmqd to start...\n",
      "[W 201027 11:28:15 manager:227] Waiting for fairing-job-l47tg-zhmqd to start...\n",
      "[W 201027 11:28:15 manager:227] Waiting for fairing-job-l47tg-zhmqd to start...\n",
      "[I 201027 11:28:16 manager:233] Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to /mnt/data/train-images-idx3-ubyte.gz\n",
      "saving to /mnt/data/train-labels-idx1-ubyte.gz\n",
      "saving to /mnt/data/t10k-labels-idx1-ubyte.gz\n",
      "saving to /mnt/data/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 201027 11:28:28 job:162] Cleaning up job fairing-job-l47tg...\n"
     ]
    }
   ],
   "source": [
    "# add for tensorboard code\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import argparse\n",
    "import json\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "# origin fairing code\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import requests\n",
    "\n",
    "class MyFashionMnist(object):\n",
    "  def train(self):\n",
    "           \n",
    "    def download(url: str, dest_folder: str):\n",
    "      if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)  # create folder if it does not exist\n",
    " \n",
    "      filename = url.split('/')[-1].replace(\" \", \"_\")  # be careful with file names\n",
    "      file_path = os.path.join(dest_folder, filename)\n",
    " \n",
    "      r = requests.get(url, stream=True)\n",
    "      if r.ok:\n",
    "        print(\"saving to\", os.path.abspath(file_path))\n",
    "        with open(file_path, 'wb') as f:\n",
    "          for chunk in r.iter_content(chunk_size=1024 * 8):\n",
    "            if chunk:\n",
    "              f.write(chunk)\n",
    "              f.flush()\n",
    "              os.fsync(f.fileno())\n",
    "      else:  # HTTP status code 4XX/5XX\n",
    "        print(\"Download failed: status code {}\\n{}\".format(r.status_code, r.text))\n",
    "        \n",
    "    download(\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\", dest_folder=\"/mnt/data/\")\n",
    "    download(\"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\", dest_folder=\"/mnt/data/\")\n",
    "    download(\"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\", dest_folder=\"/mnt/data/\")\n",
    "    download(\"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\", dest_folder=\"/mnt/data/\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if os.getenv('FAIRING_RUNTIME', None) is None:\n",
    "        from kubeflow import fairing\n",
    "        from kubeflow.fairing.kubernetes import utils as k8s_utils\n",
    "        \n",
    "        DOCKER_REGISTRY = 'kubeflow-registry.default.svc.cluster.local:30000'   # 프라이빗 레지스트리\n",
    "\n",
    "        fairing.config.set_builder(\n",
    "            'append',\n",
    "            image_name='datadownload-job', # here \n",
    "            base_image='brightfly/kubeflow-jupyter-lab:tf2.0-cpu',\n",
    "            registry=DOCKER_REGISTRY, \n",
    "            push=True\n",
    "        )\n",
    "        # cpu 1, memory 5GiB\n",
    "        fairing.config.set_deployer('job',\n",
    "                                    namespace='admin', # here\n",
    "                                    pod_spec_mutators=[\n",
    "                                        k8s_utils.get_resource_mutator(cpu=1,  # here\n",
    "                                                                       memory=5)]\n",
    "                                   )\n",
    "        fairing.config.run()\n",
    "    else:\n",
    "        remote_train = MyFashionMnist()\n",
    "        remote_train.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
